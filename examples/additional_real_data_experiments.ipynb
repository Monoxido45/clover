{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional real dataset results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from nonconformist.cp import IcpRegressor\n",
    "from nonconformist.nc import NcFactory\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-v0_8-white\")\n",
    "\n",
    "from clover.locart import LocalRegressionSplit, LocartSplit, MondrianRegressionSplit, RegressionSplit\n",
    "from acpi import ACPI\n",
    "from clover.scores import RegressionScore, LocalRegressionScore\n",
    "import time\n",
    "\n",
    "from clover.locart import LocartSplit, MondrianRegressionSplit\n",
    "from clover.scores import RegressionScore\n",
    "from clover.utils import compute_interval_length, split, smis\n",
    "import gc\n",
    "\n",
    "original_path = os.getcwd()\n",
    "\n",
    "# figure path\n",
    "images_dir = \"figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function to run big dataset experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_main_metrics_real(\n",
    "    data_name,\n",
    "    is_fitted = True,\n",
    "    figname_tree = \"tree\",\n",
    "    base_model = RandomForestRegressor,\n",
    "    sig = 0.1, \n",
    "    test_size = 0.2,\n",
    "    calib_size = 0.5, \n",
    "    random_seed = 1250,\n",
    "    split_calib = False,\n",
    "    plot_tree = False,\n",
    "    nbins = 30,\n",
    "    criterion = \"squared_error\",\n",
    "    max_depth = None,\n",
    "    max_leaf_nodes = None,\n",
    "    min_samples_leaf = 150,\n",
    "    prune = True,\n",
    "    random_projections=False,\n",
    "    h=20,\n",
    "    m=300,\n",
    "    n_estimators = 100,\n",
    "    **kwargs):\n",
    "\n",
    "    # importing data, selecting some rows and then splitting\n",
    "    data_path = os.path.normpath(os.getcwd() + os.sep + os.pardir) + \"/data/processed/\" + data_name + \".csv\"\n",
    "\n",
    "    # reading data using pandas\n",
    "    data = pd.read_csv(data_path)\n",
    "    y = data[\"target\"].to_numpy()\n",
    "    X = (data.\n",
    "    drop(\"target\", axis = 1).\n",
    "    to_numpy())\n",
    "\n",
    "    print(\"Number of samples used for training and calibration: {}\".format((1 - test_size)*X.shape[0]))\n",
    "    print(\"Number of samples used for testing: {}\".format(test_size*X.shape[0]))\n",
    "\n",
    "    # splitting data into train, calibration and test\n",
    "    data = split(X, y, test_size, calib_size, calibrate = True, random_seed = random_seed)\n",
    "\n",
    "    if data_name == \"amazon\":\n",
    "        X_train = data[\"X_train\"].flatten()\n",
    "        X_test = data[\"X_test\"].flatten()\n",
    "        X_calib = data[\"X_calib\"].flatten()\n",
    "\n",
    "        tfidf = TfidfVectorizer(max_features=500)\n",
    "        X_train = tfidf.fit_transform(X_train).toarray()\n",
    "        X_test = tfidf.transform(X_test).toarray()\n",
    "        X_calib = tfidf.transform(X_calib).toarray()\n",
    "        features = tfidf.get_feature_names_out()\n",
    "        np.savetxt(f\"data/processed/amazon_features_test\", features, fmt=\"%s\")\n",
    "\n",
    "        data[\"X_train\"] = X_train\n",
    "        data[\"X_test\"] = X_test\n",
    "        data[\"X_calib\"] = X_calib\n",
    "\n",
    "    # setting seed\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "\n",
    "    model = base_model(**kwargs).fit(data[\"X_train\"], data[\"y_train\"])\n",
    "\n",
    "    # fitting mondrian regression split\n",
    "    print(\"Fitting mondrian regression split\")\n",
    "    start_mondrian_split = time.time()\n",
    "    micp = MondrianRegressionSplit(model, is_fitted = is_fitted, alpha = sig, k = nbins, **kwargs)\n",
    "    micp.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    micp.calibrate(data[\"X_calib\"], data[\"y_calib\"])\n",
    "\n",
    "    end_mondrian_split = time.time() - start_mondrian_split\n",
    "    print(\"Time Elapsed to fit mondrian regression split: \", end_mondrian_split)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_mondrian_split = time.time()\n",
    "    # predictions for empirical metrics\n",
    "    micp_pred = micp.predict(data[\"X_test\"])\n",
    "\n",
    "    # smis\n",
    "    micp_smis = smis(micp_pred, data[\"y_test\"], alpha = sig)\n",
    "        \n",
    "\n",
    "    # mean interval length\n",
    "    micp_interval_len = np.mean(compute_interval_length(micp_pred))\n",
    "\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= micp_pred[:, 0], \n",
    "        data[\"y_test\"] <= micp_pred[:, 1]) + 0\n",
    "    micp_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    micp_interval_len_cover = np.mean(compute_interval_length(micp_pred[cover_idx]))\n",
    "\n",
    "\n",
    "    end_mondrian_split = time.time() - start_mondrian_split\n",
    "    print(\"Time Elapsed to compute statistics for mondrian regression split: \", end_mondrian_split)\n",
    "\n",
    "    # deleting mondrian objects\n",
    "    del micp\n",
    "    del micp_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Fitting locart\")\n",
    "    start_loc = time.time()\n",
    "    # fitting locart\n",
    "    locart_obj = LocartSplit(nc_score = RegressionScore, base_model = model, is_fitted = is_fitted, \n",
    "                             alpha = sig, split_calib = split_calib, **kwargs)\n",
    "    locart_obj.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    locart_obj.calib(data[\"X_calib\"], data[\"y_calib\"], max_depth = max_depth, \n",
    "    max_leaf_nodes = max_leaf_nodes, min_samples_leaf = min_samples_leaf, criterion = criterion, prune_tree = prune)\n",
    "    \n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to fit Locart: \", end_loc)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_loc = time.time()\n",
    "    # predictions\n",
    "    locart_pred = np.array(locart_obj.predict(data[\"X_test\"]))\n",
    "\n",
    "    # smis\n",
    "    locart_smis = smis(locart_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= locart_pred[:, 0], \n",
    "        data[\"y_test\"] <= locart_pred[:, 1]) + 0\n",
    "    locart_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # mean interval length\n",
    "    locart_interval_len = np.mean(compute_interval_length(locart_pred))\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    locart_interval_len_cover = np.mean(compute_interval_length(locart_pred[cover_idx]))\n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to compute metrics for Locart: \", end_loc)\n",
    "\n",
    "    # deleting locart objects\n",
    "    del locart_obj\n",
    "    del locart_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "    # fitting normal difficulty locart\n",
    "    print(\"Fitting A-locart to toy example:\")\n",
    "    start_loc = time.time()\n",
    "    dlocart_obj = LocartSplit(nc_score = RegressionScore, cart_type = \"CART\", base_model = model, is_fitted = is_fitted,\n",
    "                               alpha = sig, split_calib = split_calib, \n",
    "                              weighting = True, **kwargs)\n",
    "    dlocart_obj.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    dlocart_obj.calib(data[\"X_calib\"], data[\"y_calib\"], max_depth = max_depth, \n",
    "    max_leaf_nodes = max_leaf_nodes, min_samples_leaf = min_samples_leaf, criterion = criterion, prune_tree = prune)\n",
    "    \n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to fit A-Locart: \", end_loc)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_loc = time.time()\n",
    "    # predictions\n",
    "    dlocart_pred = np.array(dlocart_obj.predict(data[\"X_test\"]))\n",
    "\n",
    "    # smis\n",
    "    dlocart_smis = smis(dlocart_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # mean interval length\n",
    "    dlocart_interval_len = np.mean(compute_interval_length(dlocart_pred))\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= dlocart_pred[:, 0], \n",
    "        data[\"y_test\"] <= dlocart_pred[:, 1]) + 0\n",
    "    dlocart_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    dlocart_interval_len_cover = np.mean(compute_interval_length(dlocart_pred[cover_idx]))\n",
    "\n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to compute metrics for A-Locart: \", end_loc)\n",
    "    # deleting alocart objects\n",
    "    del dlocart_obj\n",
    "    del dlocart_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "    # fitting normal loforest \n",
    "    print(\"Fitting loforest\")\n",
    "    start_loc = time.time()\n",
    "    # fitting loforest\n",
    "    loforest_obj = LocartSplit(nc_score = RegressionScore, cart_type = \"RF\", base_model = model, is_fitted = is_fitted, \n",
    "                             alpha = sig, split_calib = split_calib, **kwargs)\n",
    "    loforest_obj.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    loforest_obj.calib(data[\"X_calib\"], data[\"y_calib\"], max_depth = max_depth, \n",
    "    max_leaf_nodes = max_leaf_nodes, min_samples_leaf = min_samples_leaf, criterion = criterion, prune_tree = prune, n_estimators = n_estimators)\n",
    "    \n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to fit Loforest: \", end_loc)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_loc = time.time()\n",
    "    # predictions\n",
    "    loforest_pred = np.array(loforest_obj.predict(data[\"X_test\"]))\n",
    "\n",
    "    # smis\n",
    "    loforest_smis = smis(loforest_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= loforest_pred[:, 0], \n",
    "        data[\"y_test\"] <= loforest_pred[:, 1]) + 0\n",
    "    loforest_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # mean interval length\n",
    "    loforest_interval_len = np.mean(compute_interval_length(loforest_pred))\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    loforest_interval_len_cover = np.mean(compute_interval_length(loforest_pred[cover_idx]))\n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to compute metrics for Loforest: \", end_loc)\n",
    "\n",
    "    # deleting loforest objects\n",
    "    del loforest_obj\n",
    "    del loforest_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Fitting A-Loforest\")\n",
    "    start_loc = time.time()\n",
    "    # fitting locart\n",
    "    aloforest_obj = LocartSplit(nc_score = RegressionScore, cart_type = \"RF\", base_model = model, is_fitted = is_fitted, \n",
    "                             alpha = sig, split_calib = split_calib, weighting = True, **kwargs)\n",
    "    aloforest_obj.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    aloforest_obj.calib(data[\"X_calib\"], data[\"y_calib\"], max_depth = max_depth, \n",
    "    max_leaf_nodes = max_leaf_nodes, min_samples_leaf = min_samples_leaf, criterion = criterion, prune_tree = prune, n_estimators = n_estimators)\n",
    "    \n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to fit A-Loforest: \", end_loc)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_loc = time.time()\n",
    "    # predictions\n",
    "    aloforest_pred = np.array(aloforest_obj.predict(data[\"X_test\"]))\n",
    "\n",
    "    # smis\n",
    "    aloforest_smis = smis(aloforest_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= aloforest_pred[:, 0], \n",
    "        data[\"y_test\"] <= aloforest_pred[:, 1]) + 0\n",
    "    aloforest_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # mean interval length\n",
    "    aloforest_interval_len = np.mean(compute_interval_length(aloforest_pred))\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    aloforest_interval_len_cover = np.mean(compute_interval_length(aloforest_pred[cover_idx]))\n",
    "    end_loc = time.time() - start_loc\n",
    "    print(\"Time Elapsed to compute metrics for A-Loforest: \", end_loc)\n",
    "\n",
    "    # deleting a-loforest objects\n",
    "    del aloforest_obj\n",
    "    del aloforest_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    print(\"Fitting regression split\")\n",
    "    start_split = time.time()\n",
    "    icp = RegressionSplit(base_model = model, alpha = sig, is_fitted = True)\n",
    "    icp.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    icp.calibrate(data[\"X_calib\"], data[\"y_calib\"])\n",
    "\n",
    "    end_split = time.time() - start_split\n",
    "    print(\"Time Elapsed to fit regression split: \", end_split)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_split = time.time()\n",
    "    # predictions\n",
    "    icp_pred = icp.predict(data[\"X_test\"])\n",
    "\n",
    "    # smis\n",
    "    icp_smis = smis(icp_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # ICP interval length\n",
    "    icp_interval_len = np.mean(compute_interval_length(icp_pred))\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= icp_pred[:, 0], \n",
    "        data[\"y_test\"] <= icp_pred[:, 1]) + 0\n",
    "    icp_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    icp_interval_len_cover = np.mean(compute_interval_length(icp_pred[cover_idx]))\n",
    "\n",
    "    end_split = time.time() - start_split\n",
    "    print(\"Time Elapsed to compute statistics for regression split: \", end_split)\n",
    "\n",
    "    # deleting ICP objects\n",
    "    del icp\n",
    "    del icp_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "    # fitting wighted regression split\n",
    "    print(\"Fitting weighted regression split\")\n",
    "    start_weighted_split = time.time()\n",
    "    wicp = LocalRegressionSplit(model, is_fitted = is_fitted, alpha = sig, **kwargs)\n",
    "    wicp.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    wicp.calibrate(data[\"X_calib\"], data[\"y_calib\"])\n",
    "\n",
    "    end_weighted_split = time.time() - start_weighted_split\n",
    "    print(\"Time Elapsed to fit weighted regression split: \", end_weighted_split)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_weighted_split = time.time()\n",
    "    # predictions\n",
    "    wicp_pred = wicp.predict(data[\"X_test\"])\n",
    "\n",
    "    # smis\n",
    "    wicp_smis = smis(wicp_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # ICP interval length\n",
    "    wicp_interval_len = np.mean(compute_interval_length(wicp_pred))\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= wicp_pred[:, 0], \n",
    "        data[\"y_test\"] <= wicp_pred[:, 1]) + 0\n",
    "    wicp_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    wicp_interval_len_cover = np.mean(compute_interval_length(wicp_pred[cover_idx]))\n",
    "    end_weighted_split = time.time() - start_weighted_split\n",
    "    print(\"Time Elapsed to compute statistics for weighted regression split: \", end_weighted_split)\n",
    "\n",
    "    # deleting WICP objects\n",
    "    del wicp\n",
    "    del wicp_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    start_loc = time.time()\n",
    "\n",
    "    print(\"Fitting W-LOFOREST\")\n",
    "    wlocart_obj = LocartSplit(\n",
    "        nc_score=LocalRegressionScore,\n",
    "        cart_type=\"RF\",\n",
    "        base_model=model,\n",
    "        is_fitted=is_fitted,\n",
    "        alpha=sig,\n",
    "        split_calib=split_calib,\n",
    "        **kwargs,\n",
    "    )\n",
    "    wlocart_obj.fit(data[\"X_train\"], data[\"y_train\"])\n",
    "    wlocart_obj.calib(\n",
    "        data[\"X_calib\"],\n",
    "        data[\"y_calib\"],\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        criterion=criterion,\n",
    "        prune_tree=prune,\n",
    "        random_projections=random_projections,\n",
    "        n_estimators = n_estimators,\n",
    "        m=m,\n",
    "        h=h,\n",
    "    )\n",
    "\n",
    "    end_weighted_split = time.time() - start_weighted_split\n",
    "    print(\"Time Elapsed to fit W-LOFOREST: \", end_weighted_split)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_weighted_split = time.time()\n",
    "    # predictions\n",
    "    wlocart_pred = wlocart_obj.predict(data[\"X_test\"])\n",
    "\n",
    "    # smis\n",
    "    wlocart_smis = smis(wlocart_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # ICP interval length\n",
    "    wlocart_interval_len = np.mean(compute_interval_length(wlocart_pred))\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= wlocart_pred[:, 0], \n",
    "        data[\"y_test\"] <= wlocart_pred[:, 1]) + 0\n",
    "    wlocart_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    wlocart_interval_len_cover = np.mean(compute_interval_length(wlocart_pred[cover_idx]))\n",
    "    end_weighted_split = time.time() - start_weighted_split\n",
    "    print(\"Time Elapsed to compute statistics for W-LOFOREST: \", end_weighted_split)\n",
    "\n",
    "    # deleting WICP objects\n",
    "    del wlocart_obj\n",
    "    del wlocart_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Fitting ACPI\")\n",
    "    start_weighted_split = time.time()\n",
    "    acpi = ACPI(model_cali = model, n_estimators = 100)\n",
    "    acpi.fit(data[\"X_test\"], data[\"y_test\"], nonconformity_func = None)\n",
    "    acpi.fit_calibration(data[\"X_calib\"], data[\"y_calib\"], quantile = 1 - sig, only_qrf = True)\n",
    "\n",
    "    end_weighted_split = time.time() - start_weighted_split\n",
    "    print(\"Time Elapsed to fit ACPI: \", end_weighted_split)\n",
    "\n",
    "    print(\"Computing metrics\")\n",
    "    start_weighted_split = time.time()\n",
    "    # predictions\n",
    "    acpi_pred = np.stack((acpi.predict_pi(data[\"X_test\"], method=\"qrf\")), axis=-1)\n",
    "\n",
    "    # smis\n",
    "    acpi_smis = smis(acpi_pred, data[\"y_test\"], alpha = sig)\n",
    "\n",
    "    # ICP interval length\n",
    "    acpi_interval_len = np.mean(compute_interval_length(acpi_pred))\n",
    "\n",
    "    # marginal coverage\n",
    "    marg_cover = np.logical_and(data[\"y_test\"] >= acpi_pred[:, 0], \n",
    "        data[\"y_test\"] <= acpi_pred[:, 1]) + 0\n",
    "    acpi_ave_marginal_cov = np.mean(\n",
    "        marg_cover\n",
    "    )\n",
    "\n",
    "    # interval length | coveraqe\n",
    "    cover_idx = np.where(marg_cover == 1)\n",
    "    acpi_interval_len_cover = np.mean(compute_interval_length(acpi_pred[cover_idx]))\n",
    "    end_weighted_split = time.time() - start_weighted_split\n",
    "    print(\"Time Elapsed to compute statistics for ACPI: \", end_weighted_split)\n",
    "\n",
    "    # deleting ACPI objects\n",
    "    del acpi\n",
    "    del acpi_pred\n",
    "    del cover_idx\n",
    "    del marg_cover\n",
    "    gc.collect()\n",
    "    \n",
    "    all_results =  pd.DataFrame(data = {\"Methods\":[\"LOCART\", \"A-LOCART\", \"LOFOREST\", \"A-LOFOREST\",\n",
    "                                                   \"Regresion split\", \"Weighted regression split\", \n",
    "                                                   \"Mondrian regression split\", \"ACPI\", \"W-LOFOREST\"],\n",
    "    \"Average marginal coverage\":[locart_ave_marginal_cov, dlocart_ave_marginal_cov, loforest_ave_marginal_cov, aloforest_ave_marginal_cov, \n",
    "                                 icp_ave_marginal_cov, wicp_ave_marginal_cov, micp_ave_marginal_cov, acpi_ave_marginal_cov,\n",
    "                                 wlocart_ave_marginal_cov],\n",
    "    \"Average interval length\":[locart_interval_len, dlocart_interval_len, loforest_interval_len, aloforest_interval_len,\n",
    "                               icp_interval_len, wicp_interval_len, micp_interval_len, acpi_interval_len,\n",
    "                               wlocart_interval_len],\n",
    "    \"Average interval length given coverage\":[locart_interval_len_cover, dlocart_interval_len_cover, loforest_interval_len_cover, aloforest_interval_len_cover,\n",
    "                                              icp_interval_len_cover, wicp_interval_len_cover, micp_interval_len_cover, acpi_interval_len_cover,\n",
    "                                              wlocart_interval_len_cover],\n",
    "    \"SMIS values\":[locart_smis, dlocart_smis, loforest_smis, aloforest_smis, icp_smis, wicp_smis, micp_smis, acpi_smis, wlocart_smis]})\n",
    "        \n",
    "    # plotting tree to visualize partitions\n",
    "    if plot_tree:\n",
    "        plt.figure(figsize=(25, 20))\n",
    "        locart_obj.plot_locart()\n",
    "        plt.savefig(f\"{images_dir}/{figname_tree}\")\n",
    "        plt.show()\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running kernel dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples used for training and calibration: 193280.0\n",
      "Number of samples used for testing: 48320.0\n",
      "Fitting mondrian regression split\n",
      "Time Elapsed to fit mondrian regression split:  8.87926197052002\n",
      "Computing metrics\n",
      "Time Elapsed to compute statistics for mondrian regression split:  2.7890756130218506\n",
      "Fitting locart\n",
      "Time Elapsed to fit Locart:  24.89926505088806\n",
      "Computing metrics\n",
      "Time Elapsed to compute metrics for Locart:  1.228313684463501\n",
      "Fitting A-locart to toy example:\n",
      "Time Elapsed to fit A-Locart:  37.11011481285095\n",
      "Computing metrics\n",
      "Time Elapsed to compute metrics for A-Locart:  2.614086151123047\n",
      "Fitting loforest\n",
      "Time Elapsed to fit Loforest:  21.565516233444214\n",
      "Computing metrics\n",
      "Time Elapsed to compute metrics for Loforest:  1.9205327033996582\n",
      "Fitting A-Loforest\n",
      "Time Elapsed to fit A-Loforest:  29.977654218673706\n",
      "Computing metrics\n",
      "Time Elapsed to compute metrics for A-Loforest:  3.3845417499542236\n",
      "Fitting regression split\n",
      "Time Elapsed to fit regression split:  2.385746955871582\n",
      "Computing metrics\n",
      "Time Elapsed to compute statistics for regression split:  1.1887173652648926\n",
      "Fitting weighted regression split\n",
      "Time Elapsed to fit weighted regression split:  34.09426259994507\n",
      "Computing metrics\n",
      "Time Elapsed to compute statistics for weighted regression split:  2.5024139881134033\n",
      "Fitting W-LOFOREST\n",
      "Time Elapsed to fit W-LOFOREST:  54.14967656135559\n",
      "Computing metrics\n",
      "Time Elapsed to compute statistics for W-LOFOREST:  3.021519422531128\n",
      "Fitting ACPI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [19:07<00:00, 22.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed to fit ACPI:  1197.154717206955\n",
      "Computing metrics\n",
      "Time Elapsed to compute statistics for ACPI:  2.2162208557128906\n"
     ]
    }
   ],
   "source": [
    "kernel_results = obtain_main_metrics_real(data_name = \"kernel\", random_seed = 30, random_state = 45, min_samples_leaf = 150, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Average marginal coverage</th>\n",
       "      <th>Average interval length</th>\n",
       "      <th>Average interval length given coverage</th>\n",
       "      <th>SMIS values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOCART</td>\n",
       "      <td>0.901283</td>\n",
       "      <td>4.292009</td>\n",
       "      <td>4.311993</td>\n",
       "      <td>-6.411761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-LOCART</td>\n",
       "      <td>0.901987</td>\n",
       "      <td>4.019274</td>\n",
       "      <td>4.024302</td>\n",
       "      <td>-6.146922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOFOREST</td>\n",
       "      <td>0.912790</td>\n",
       "      <td>4.291809</td>\n",
       "      <td>4.262284</td>\n",
       "      <td>-6.416687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-LOFOREST</td>\n",
       "      <td>0.911341</td>\n",
       "      <td>4.029497</td>\n",
       "      <td>3.994142</td>\n",
       "      <td>-6.040283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regresion split</td>\n",
       "      <td>0.902732</td>\n",
       "      <td>4.228260</td>\n",
       "      <td>4.228260</td>\n",
       "      <td>-10.465670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Weighted regression split</td>\n",
       "      <td>0.899379</td>\n",
       "      <td>3.961186</td>\n",
       "      <td>4.023055</td>\n",
       "      <td>-5.501266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mondrian regression split</td>\n",
       "      <td>0.901966</td>\n",
       "      <td>4.152145</td>\n",
       "      <td>4.153313</td>\n",
       "      <td>-6.535449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACPI</td>\n",
       "      <td>0.921896</td>\n",
       "      <td>4.202459</td>\n",
       "      <td>4.110069</td>\n",
       "      <td>-5.962586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W-LOFOREST</td>\n",
       "      <td>0.905008</td>\n",
       "      <td>4.098669</td>\n",
       "      <td>4.190425</td>\n",
       "      <td>-5.474092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Methods  Average marginal coverage  \\\n",
       "0                     LOCART                   0.901283   \n",
       "1                   A-LOCART                   0.901987   \n",
       "2                   LOFOREST                   0.912790   \n",
       "3                 A-LOFOREST                   0.911341   \n",
       "4            Regresion split                   0.902732   \n",
       "5  Weighted regression split                   0.899379   \n",
       "6  Mondrian regression split                   0.901966   \n",
       "7                       ACPI                   0.921896   \n",
       "8                 W-LOFOREST                   0.905008   \n",
       "\n",
       "   Average interval length  Average interval length given coverage  \\\n",
       "0                 4.292009                                4.311993   \n",
       "1                 4.019274                                4.024302   \n",
       "2                 4.291809                                4.262284   \n",
       "3                 4.029497                                3.994142   \n",
       "4                 4.228260                                4.228260   \n",
       "5                 3.961186                                4.023055   \n",
       "6                 4.152145                                4.153313   \n",
       "7                 4.202459                                4.110069   \n",
       "8                 4.098669                                4.190425   \n",
       "\n",
       "   SMIS values  \n",
       "0    -6.411761  \n",
       "1    -6.146922  \n",
       "2    -6.416687  \n",
       "3    -6.040283  \n",
       "4   -10.465670  \n",
       "5    -5.501266  \n",
       "6    -6.535449  \n",
       "7    -5.962586  \n",
       "8    -5.474092  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clover_tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
